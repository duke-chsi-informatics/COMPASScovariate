---
title: "COMPASScovariate Test Simulations"
author: "Tyler Schappe"
date: "2022-11-22"
output: 
  html_document:
    code_folding: show
    toc: true
    toc_float: true
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#Build COMPASScovariate package
devtools::load_all("..")

#Source for now but will want to call using COMPASS.R eventually
source("~/project_repos/COMPASScovariate/R/COMPASS-covariate.R")
source("~/project_repos/COMPASScovariate/R/updatebeta.R")
source("~/project_repos/COMPASScovariate/R/utils.R")

library(foreach); library(doParallel); library(HMP); library(MCMCpack); library(devtools); library(ggplot2); library(tidyverse)

# install.packages("MultiRNG")
```

## Notes

**Note on iterations:** Keep only the last X iterations and use the first ones to warm up chains.

**12/13/22 To Do:**

- Create density plot of posterior for betas that have a large difference between estimated and true.
- Reduce to 2 markers = 4 cell subsets
- Modify covariates (intercept) to allow ~ 50% of gammas to be 1

### Additional Complexities

1) Smaller difference in concentration parameters between stim and unstim
2) Different number of total events and event subsets for stim and unstim samples
3) Smaller percentage of gamma = 1

**Notes from meeting on 12/21/22**

Two types of covariates -- patient characteristics and experimental design

Want some cell subsets to be 0 when covariate (age) 

HIV group (treatment group) -- more + gammas
Young people -- less + gammas
HIV group also have more young people so that without knowing (conditioning on age), there is no association with HIV group

Don't include HIV in COMPASScovariate

Treatment group (HIV): 

- Larger sigma.beta
- Larger cutoff value for beta selection
- Outcome is vector of length I -- binary
  + If gamma++ == 1, then outcome = 1; else outcome = 0


0. Remove all other covariates
1. Specify # of HIV+ and HIV-
1. Sim with age and HIV
  1. Age (X) | HIV+: Young --  rnorm(-1, 0.4) (plot values to see overlap)
  2. Age (X) | HIV-: Old --    rnorm(1, 0.4)
2. Run COMPASScovariate with just age
3. Run original COMPASS
4. Logistic regression to see if PFS scores are associated with HIV
  1. COMPASScovariate PFS -- hope to be associated with HIV
  2. COMPASS PFS -- hope to not be associated


**Notes from meeting on 1/24/23**

- Setup with age | HIV status makes sense, but we need to have the pattern emerge only when age is accounted for and have no pattern when it's not (something paradox)
- Increase the number of markers to 8 so that we don't have people randomly have none or all subsets stimulated
- Can check difference between mean.gamma for COMPASScovariate and COMPASS to identify subjects for which the model responds differently

**Notes from meeting on 1/31/23**

- Consider clinical outcome to be protection status, defined as not becoming infected when challenged
  + Assume protection comes from a robust immune response == high polyfunctional score
  + Probability of stimulation is a function of age
- The chain of causality is: Age -> Prob. stim -> PFS -> Protection
  + We created a set of DAGs that is uploaded as a PDF to /incubator/sim/DAG.pdf
  + In the DAG, Age is a classic confounder between PFS and protection
  + Practically speaking, we hope that COMPASS will give PFS such that the relationship with protection is weak, but COMPASScovariate will give improved PFS such that the relationship is stronger
- For simulating true PFS from Prob. stim, can use the PolyfunctionalScore() function but pass it the true Gamma matrix (it normally uses the estimated mean gamma matrix)
- For simulating true Protection status, need to choose a true beta and use a logistic regression-type link where PFS is associated with higher probability of Protection
- Lynn also wants to add more noise the signal of the magnitude of change in probability between stim and unstim, which would translate to drawing ps.logmu.diff from some distribution with a small amount of variance
- To do:
  + Add variance to drawing ps.logmu.diff
  + Add generating true PFS scores using true gamma matrix
  + Add true betas for relationship between PFS and probability of protection
  + Add generating true protection status from PFS given the beta

**Notes from meeting on 2/7/23**

- Modify concentration parameters so that the amount added (diff) is positively associated with age. Make it the same for all cell subsets. 

**Notes from meeting on 2/14/23:**

- COMPASScovariate cannot adjust for confounding/bias because of the within-subject application of the stimulation treatment -- since every subject is given both treatment (stim) and control (unstim), there is basically no way a covariate can affect which exposure each subject receives. 
  + Therefore, consider the covariate as an effect modifier -- accounting for it can improve the precision of the estimates
- For ease of interpretation, change continuous covariate to binary indicator.

**Notes from meeting on 2/21/23**

- Lynn agrees precision of estimates should be a focus for COMPASScovariate
- To do:
  + Check the acceptance rate for the sampling -- if too low, may need to tune the model
  + Compare mean gamma (estimates of probability of response) to true probabilities instead of comparing gamma. Find the differences for both COMPASS and COMPASScovariate, then find the difference in those differences to look for subject-cell types. 
  + Increase magnitude of stimulation betas -- draw them from uniform(1,2)

**Notes from meeting on 2/28/23**

- Concentration_s and concentration_u are the same for all subjects, fixed not drawn from log-normal (manually specify them)
- Do not use Dirichlet-Multinomial because can't normalize p_s
- Determine p_u first, then create p_s for gamma == 1 and normalize before adding back to vector. This allows for p_s and p_u to be the same value when gamma == 1 (required by COMPASS). Because of this, there has to be more than 1 gamma == 1 because of the constraint that we can't change a single p_s without changing the others in that case.

Code from Lynn to make Kth subset have much higher counts
alpha_u[1, 1:(K - 1)] = 10 #initializaion 
  alpha_u[1, K] = 150
  
  alpha_s[1, 1:(K - 1)] = 10 #initialization 
  alpha_s[1, K] = 100
  
**Toy example for normalization**

```{r eval=FALSE, include=FALSE}
gamma = c(0, 1, 1, 0,
          1, 0, 1, 0
)

alpha.u = c(10, 10, 10, 100)
alpha.s = c(50, 50, 50, 100)

alpha.s = X

p_u = rdirichlet(n = 1, alpha = alpha.u)

p_s = p_u

p_s[2:3] = rdirichlet(n = 1, alpha = alpha.s[2:3]) * sum(p_u[gamma == 1])

sum(p_s)
```

**Notes from meeting on 3/28/23**

- Add shift of concentration parameter depending on number of subsets that are stimulated for subject -- goal is to have weight for a single stimulated subset be the same as the weight of each of the subsets when many are stimulated in order to avoid giving too much weight to subsets when only a few are stimulated for a sample. Cliburn suggested thinking about it in terms of a counterfactual when the same subject has the covariate or does not have the covariate -- the weight given in the no covariate case to each subset shouldn't be a lot larger. 
- Examine traceplots for convergence -- does covariate help convergence for clusters where not many are responding
- Color mean gamma - mean gamma plots by true gamma value
- Reduce subjects to 40
- Add logistic regression with mean_gamma as covariates (first K-1 subsets) instead of using PFS

## Simulate Data and Run COMPASScovariate

**Approach**

1) Matrix of true betas for each k-1 subset for each covariate p ~ Normal(beta.mu, beta.sigma)
    a) Model selection where any beta where |beta| < beta.selection.cutoff -> 0
2) Vector of true intercepts for each k-1 subset ~ Normal(int.mu, int.sd)
    a) int.mu is 0 to keep probability that gamma = 1 ~ 50%, which makes estimating betas easier.
3) Matrix X (I x p) of covariates with first column of 1's for intercept
4) Omega (I x K1): For each sample, for each subset, generate linear predictor as linear combination of sample's covariate values X[i,] and subset-specific true betas beta.true.final[k,]
5) gamma.m (I x K1): For each sample, for each subset, map linear predictor to probability using inverse-logit function
6) Generate unstimulated and stimulated counts from a Dirichlet-Multinomial distribution where the concentration parameters are drawn from a lognormal distribution with same logmean and logsd values.
    a) For stimulated cluster-samples (where gamma = 1), shift the logmean by ps.logmu.diff to increase the concentration parameter by exp(ps.logmu.diff).
    b) For each sample, number of stimulated and unstimulated counts ~ Normal(e.total.mu, e.total.sd). This is the total number of stim and unstim counts for each sample.
    c) For both stimluated and unstimulated, use Dirichlet-Multinomial to draw subset of stimulated and unstimulated counts ~ Normal(e.mu, e.sd). This is the number of stim and unstim counts for all K subsets. **Note:** The values of the concentration parameter can be interpreted as prior pseudo-counts and thus determine the variance among categories. Use high concentration parameter values to reduce the variance in counts among categories in resulting draws.
    d) **Important:** The Kth category is included in the draws, but has a very large concentration parameter compared to rest of the categories so that the number of counts is much larger. This is to mimic real flow data where the majority of cells are in the "all negative" subset (ie. they don't belong to any of the mutually exclusive categories created by the markers of interest). We include this category because otherwise additional counts for a stimulated cell subset take away counts from only the k - 1 markers, resulting in significantly reduced counts for them (Lynn's original method). Here, the counts for the stimulated cell subset are "taken" from all other subsets with probability proportionate to the concentration parameters. Since the kth subset is given such a high concentration, it is much more likely that the counts are "taken" from that category, thus allowing the counts for the k - 1 subsets to remain constant (with some noise) between unstim and stim samples if they are not truely stimulated. 
  

### Set Fixed Parameters

```{r}
set.seed(111)
#Get number of iter and reps from 'run_simu_cov.sh'
# iter = as.integer(Sys.getenv("ITER")) #Number of COMPASScovariate iterations per replicate
# rep = as.integer(Sys.getenv("REP"))   #Number of COMPASScovariate replicates
# sim.rep = as.integer(Sys.getenv("SIM_REP")) #Number of replicates per parameter combination

iter = 5000 #Number of COMPASScovariate iterations per replicate
rep = 2     #Number of COMPASScovariate replicates
sim.rep = 1

#Total counts
e.total.mu = 10000 #Mean total number of events per subject
e.total.sd = 10   #SD of total number of events per subject
e.subset.mu = 3000 #Mean number of events per subject that are not in the Kth category (all negative set)
e.subset.sd = 5   #SD of number of events per subject that are not in the Kth category (all negative set)

#Betas
beta.mu = 0
beta.sigma = 0.8
beta.unif.min = 2
beta.unif.max = 3
int.mu = 0
int.sd = 0.1
beta.selection.cutoff = 0.2

#HIV+ and HIV- subjects
prob.hiv.pos = 0.5
age.mean.hiv.neg = 0.5
age.mean.hiv.pos = -0.5
age.sd = 0.8

### Pu and Ps
#Concentration params drawn from lognormal
pu.logmu = log(20)
p.logsd = 0.03
#Diff in means of lognormal a function of covariate with true intercepts and slopes below
ps.logmu.diff.beta = c(0.5, 1)
ps.logmu.diff.sd = 0.1 #Error term for relationship between shift in concentration param and covariate

### Protection
beta.p = c(-2, 2)

#Figure output
out.dir = file.path("/work",
                        Sys.getenv("USER"),
                        "COMPASScovariate-sim",
                        "output"
)
dir.create(out.dir,
           showWarnings = FALSE,
           recursive = TRUE
)
```

### Generate combinations of simulation parameters

```{r}
#Get number of threads from SLURM scheduler as # of CPUs allocated
# threads = as.integer(Sys.getenv("SLURM_CPUS_PER_TASK"))
threads = 2

#Make a single df of all combinations of parameters
sim.pars <- expand.grid(I = c(200),#, 60, 100, 200),   #Number of subjects
                        K = c(16),        #Number of unique cell subsets
                        p = c(0)         #Number of covariations IN ADDITION TO AGE | HIV status
            )

#Repeat the df to create replicates for each combination -- repeat 'sim.rep' times
sim.pars <- do.call('rbind', lapply(1:sim.rep, FUN = function(simrep) {
  data.frame(
    sim_rep = simrep,
    sim.pars
  )
  })
)
```

### Run Simulation

```{r}
cl <- makeCluster(threads)
registerDoParallel(cl)

sim.out.list <- foreach(s = 1:nrow(sim.pars), .packages = c("COMPASS", "dplyr", "tidyr")) %dopar% {

  I <- sim.pars[s,]$I ## sample size i.e., #subjects; I = 30
  K <- sim.pars[s,]$K ## number of cell categories: K = 16
  p <- sim.pars[s,]$p + 1 # number of covariates # larger p
  sim_rep <- sim.pars[s,]$sim_rep
  K1 = K-1 ## number of cell categories minus one (last one is baseline)
  
  ### True Regression Coefs
  #Intercepts
  int.true = rnorm(n = K1,
                   mean = int.mu,
                   sd = int.sd
                   )
  
  #Covariate betas
  # beta.true = matrix(rnorm(n = K1*(p),
  #                          mean = beta.mu, 
  #                          sd = beta.sigma), 
  #                    nrow = K1
  # )
  beta.true = matrix(runif(n = K1*(p),
                           min = beta.unif.min,
                           max = beta.unif.max
                     ),
                     nrow = K1
  )
  
  #Variable selection -- if |true beta| < 0.5, then true beta = 0
  beta.true.selection = apply(beta.true, MARGIN = c(1,2), FUN = function(x) ifelse(abs(x) < beta.selection.cutoff, 0, x))
  
  #Bind intercept betas to other betas
  beta.true.final <- cbind(int.true, beta.true.selection)
  
  ###Make covariates
  #Add int and HIV status
  covar <- data.frame(
                  #First column is 1s for intercept
                  int = rep(1, I*1),
                  #HIV status
                  hiv = sample(c(0, 1), size = I, replace = T, prob = c(prob.hiv.pos, 1-prob.hiv.pos)),
                  #Age
                  age = rep(NA, I)
  )
  
  #Add remainder of covariates if any
  if (p > 1) {
    covar <- cbind(covar,
                   matrix(rnorm(n = I),
                         ncol = p-1,
                         nrow = I,
                         dimnames = list(NULL, paste0("V", 2:(p)))
                  )
    )
  }
  
  #Add age | HIV
  covar <- covar %>%
            mutate(age = replace(age, hiv == 0, rnorm(n = sum(hiv == 0), 
                                                     mean = age.mean.hiv.neg, 
                                                     sd = age.sd
                                                     )
                                 ),
                   age = replace(age, hiv == 1, rnorm(n = sum(hiv == 1),
                                                     mean = age.mean.hiv.pos,
                                                     sd = age.sd
                                                     )
                                 )
            )
  #Plot age | HIV
  # covar %>%
  #   ggplot(aes(x = age,
  #              fill = as.factor(hiv))
  #   )+
  #   geom_density(alpha = 0.7)+
  #   theme_bw()
  
  #Matrix matrix version without HIV status
  X = covar %>%
        dplyr::select(-age) %>%
        as.matrix()
  
  ### True Gamma Matrix
  #Generate omega_ik -- probability that gamma_ik = 1
  
  #  1. p covariates from subject i x betas for p coefficients for cluster k gives linear predictor for cluster k in subject i
  #  2. Inverse-logit transform linear predictor to obtain prob that gamma = 1 (true diff between stim and unstim) for cluster k in subject i
  
  #Empty matrix to hold omega
  omega <- matrix(NA,
                  nrow = I,
                  ncol = K1
                  )
  
  #Empty matrix to hold gamma
  gamma.m <- matrix(NA,
                       nrow = I,
                       ncol = K1
                       )
  
  for (i in 1:I) {
    for (k in 1:K1) {
      #Generate linear predictor and prob via inverse link
      omega[i,k] <- binomial()$linkinv(X[i, ] %*% beta.true.final[k,]) #p covariates from ith subject x betas for p coefficients for kth cluster gives linear predictor
      
      #Generate gamma as Bernoulli RV with probs from omega
      gamma.m[i,k] <- rbinom(n = 1,
                             size = 1,
                             prob = omega[i,k]
                             )
    }
  }
  
  
  ### True Counts
  #Empty matrices for stim and unstim counts. **Note:** Create K columns with 0s, not K - 1
  n_u <- matrix(0,
                nrow = I,
                ncol = K)
  
  n_s <- matrix(0,
                nrow = I,
                ncol = K)
  
  #### Unstimulated
  ##Generate unstimulated count values for each subject
  #Generate total counts
  Nu = ceiling(
        rnorm(mean = e.total.mu, 
              sd = e.total.sd,
              n = I)
  )
  
  Nu.subset = ceiling(
                rnorm(mean = e.subset.mu, 
                      sd = e.subset.sd,
                      n = I
                ) 
  )
  
  ##Loop over each sample and do two things:
  
  #  1. Create a vector of length K - 1 (not K) of concentration parameters drawn from a lognormal distribution with an unstimulated-specific log-mean.
  #  2. Using the vector of concentration parameters, draw a vector of counts of length K - 1 (not K) from a Dirichlet-Multinomial distribution and fill the first K - 1 columns of the ith row of n_u
  
  #Notes:
  
  # - Leave the last column as 0 for all negative cell subset
  # - Use Nu instead of Nu.subset because now Kth category included in DM-generated data
  # - For the Kth subset, draw from lognormal with ps.logmu * 3 so that concentration values are MUCH higher for this subset, giving a very large number of counts. This is important to allow stimulated subsets to have higher counts without lowering the counts of unstimulated subsets because they are zero sum -- the probability of "taking" those counts from the null subset is much higher if it has significantly higher counts than the rest.
  
  concentration_u = matrix(NA,
                           nrow = I,
                           ncol = K
                    )
  
  for (i in 1:I) {
    concentration_u[i,1:K1] = rlnorm(n = K1, 
                   meanlog = (pu.logmu), 
                   sdlog = p.logsd
    )
    
    concentration_u[i,K] = rlnorm(n = 1,
                                  meanlog = pu.logmu*3,
                                  sdlog = p.logsd
    )
    #HMP version
    n_u[i,1:K] = t(matrix(HMP::Dirichlet.multinomial(Nrs = Nu[i], shape = concentration_u[i,])))
    
    # #MultiRNG version
    # n_u[i,1:K] = MultiRNG::draw.dirichlet.multinomial(N = Nu[i],                    #Total counts
    #                                                        no.row = 1,                      #Sample size
    #                                                        d = length(concentration_u[i,]), #Number of categories (same as length of concentration vector)
    #                                                        alpha = concentration_u[i,],     #Concentration vector
    #                                                        beta = 1                         #Common shape parameter
    #                                                             )
  }
  
  #### Stimulated
  ##Generate stimulated count values for each subject
  #Generate total counts
  Ns = ceiling(
        rnorm(mean = e.total.mu, 
              sd = e.total.sd,
              n = I)
  )
  
  Ns.subset = ceiling(
                rnorm(mean = e.subset.mu, 
                      sd = e.subset.sd,
                      n = I
                ) 
  )
  
  ##Loop over each sample and do two things:
  
  #  1. Create a vector of length K - 1 (not K) of concentration parameters drawn from a lognormal distribution with an unstimulated-specific log-mean.
  #  2. Using the vector of concentration parameters, draw a vector of counts of length K - 1 (not K) from a Dirichlet-Multinomial distribution and fill the first K - 1 columns of the ith row of n_u
  
  #Notes:
  
  #  - Leave the last column as 0
  #  - Concentration is shifted by amount which is a linear function of age if gamma = 1. Add some random noise to relationship between age and amount of concentration shifted.
  #  - Use Nu instead of Nu.subset because now Kth category included in DM-generated data
  #  - For the Kth subset, draw from lognormal with ps.logmu * 3 so that concentration values are MUCH higher for this subset, giving a very large number of counts. This is important to allow stimulated subsets to have higher counts without lowering the counts of unstimulated subsets because they are zero sum -- the probability of "taking" those counts from the null subset is much higher if it has significantly higher counts than the rest.
  
  concentration_s = matrix(NA,
                           nrow = I,
                           ncol = K
                    )
  
  #Loop over i rows and j columns in concentration_s matrix
  for (i in 1:I) {
    for (j in 1:K1) {
      concentration_s[i, j] = 
              #Draw the concentration value for the current cell (n=1) from lognormal
              rlnorm(n = 1, 
                     #Mean of lognormal is pu.logmu
                     meanlog = (pu.logmu + 
                                #If the corresponding gamma.m cell is 1, then subset is stimulated
                                ifelse(gamma.m[i,j] == 1,
                                       #If stimulated, add a diff value to mean of lognormal that is a linear function of age
                                       X[i, ] %*% ps.logmu.diff.beta +
                                         #Add small amount of noise to relationship between age and diff value
                                         rnorm(mean = 0,
                                               sd = ps.logmu.diff.sd,
                                               n = 1
                                         ),
                                       #Else if not stimulated, add 0
                                       0
                                )
                     ),
                     sdlog = p.logsd
      )
    } #End loop over j columns
    
    #Draw concentration for null subset (Kth column) from lognormal with mean pu.logmu * constant
    concentration_s[i, K] = rlnorm(n = 1,
                                  meanlog = pu.logmu*3,
                                  sdlog = p.logsd
    )
    #HMP version
    n_s[i,1:K] = t(matrix(HMP::Dirichlet.multinomial(Nrs = Ns[i], shape = concentration_s[i,])))
    
    # #MultiRNG version
    # n_s[i,1:K] = MultiRNG::draw.dirichlet.multinomial(N = Ns[i],                #Total counts
    #                                                    no.row = 1,                      #Sample size
    #                                                    d = length(concentration_s[i,]), #Number of categories (same as length of concentration vector)
    #                                                    alpha = concentration_s[i,],     #Concentration vector
    #                                                    beta = 1                         #Common shape parameter
    #                                                             )
  
  } #End loop over i rows
  
  ## Add colnames
  colnames(n_s) = 1:K
  colnames(n_u) = 1:K
  
  ## Add rownames
  rownames(n_s) = 1:I
  rownames(n_u) = 1:I
  
  ##################################
  ## Generate Polyfunctional Scores
  ##################################
  
  #Function
  PolyfunctionalityScore.default <- function(categories, gamma) {
    degree <- categories[, "Counts"]
    n <- ncol(categories) - 1
    pfs <-
      apply(gamma, 1, function(row) {
        ## (2 / (n+1)) is a factor that normalized the score between 0 and 1
        sum(row * degree / choose(n, degree)) / n * (2 / (n + 1))
      })
    
    return(pfs)
  }
  
  #Calculate the categories (copied from simpleCOMPASS.R)
  marker_names <- unique(
    unlist( strsplit( gsub("!", "", colnames(n_s)), "&", fixed=TRUE ) )
  )
  n_markers <- length(marker_names)
  cats <- as.data.frame( matrix(0, nrow=ncol(n_s), ncol=n_markers) )
  rownames(cats) <- colnames(n_s)
  colnames(cats) = marker_names
  for (i in seq_along(cats)) {
    #cats[, i] <- as.integer(grepl( paste0( colnames(cats)[i], "+" ), rownames(cats), fixed=TRUE ))
    cats[,i] <-
      as.integer(!grepl(paste0("!",colnames(cats)[i],"(&|$)+"),rownames(cats),fixed =
                          FALSE))
  }
  cats$Counts <- apply(cats, 1, sum)
  cats <- as.matrix(cats)
  
  #Modify gamma.m to add a column for the null subset (all 0s because none are stimulated)
  gamma.m.mod <- cbind(gamma.m, rep(0, nrow(gamma.m)))
  
  #Calulate PFS
  pfs <-
    PolyfunctionalityScore.default(categories = cats,
                                 gamma = gamma.m.mod
    )
  
  #Add intercept
  pfs <-
    data.frame(int = rep(1, I),
               pfs = pfs
    ) %>%
    as.matrix()
  
  ####################################
  ## Generate Outcome (HIV protection)
  ####################################
  #Generate linear predictor and prob via inverse link
  protect.prob <- binomial()$linkinv(pfs %*% beta.p) #p covariates from ith subject x betas for p coefficients for kth cluster gives linear predictor
  
  #Generate gamma as Bernoulli RV with probs from omega
  protect.true <- rep(NA, length(protect.prob))
  for(i in 1:length(protect.prob)) {
    protect.true[i] <-
      rbinom(n = 1,
             size = 1,
             prob = protect.prob[i]
      )
  }
  
  ##
  covar <-
    data.frame(covar,
               pfs.true = pfs,
               protect.prob.true = protect.prob,
               protect.true = protect.true
    )
  
  ########################
  ### Run COMPASScovariate
  ########################
  
  ## Make metadata for COMPASS
  metadat <- 
    covar %>%
    dplyr::select(-int) %>%
    mutate(sample.id = rownames(.))
  
  #Create a version of X without an intercept column
  X.mod = as.matrix(X[,-1])  #Use as.matrix to keep matrix format in case ncol(X.mod) = 1
  
  #COMPASScovariate
  .fit = .COMPASS.covariate(n_s = n_s, 
                            n_u = n_u,
                            X = X.mod,
                            iterations = iter, 
                            replication = rep
  )
  
  #COMPASS
  .compass_fit = SimpleCOMPASS(n_s = n_s,
                               n_u = n_u,
                               meta = metadat,
                               individual_id = "sample.id",
                               iterations = iter,
                               replications = rep
  )
  
  ###Coerce fit into output used in simpleCOMPASS.R
  fit <- list(
    fit=.fit,
    data=list(
      n_s=n_s,
      n_u=n_u,
      counts_s=rowSums(n_s),
      counts_u=rowSums(n_u),
      categories=.fit$categories,
      meta=covar
      # individual_id=individual_id
    )
  )
  class(fit) <- c("COMPASSResult")
  
  compass.fit <- list(
    fit = .compass_fit,
    data=list(
      n_s=n_s,
      n_u=n_u,
      counts_s=rowSums(n_s),
      counts_u=rowSums(n_u),
      categories=.compass_fit$categories,
      meta=covar
      # individual_id=individual_id
    )
  )
  class(compass.fit) <- c("COMPASSResult")
  
  ###################
  ### Collect Results
  ###################
  results.list <- list(fit,
                       compass.fit,
                       gamma.m,
                       omega,
                       beta.true.final,
                       beta.p,
                       I,
                       K,
                       K1,
                       p,
                       sim_rep
  )
  
  names(results.list) <- c('sim.fit',
                           'compass.fit',
                           'gamma.m',
                           'omega',
                           'beta.true.final',
                           'beta.p',
                           'I',
                           'K',
                           'K1',
                           'p',
                           'sim_rep')
  
  return(results.list)
}

stopCluster(cl)
```

**Notes on including cats**

## Examine

### Acceptance Rate

Check acceptance rate for sampler for COMPASS and COMPASScovariate (want 20% - 30%). If too low, need to tune the algorithm. 
```{r}
lapply(sim.out.list, FUN = function(fit) {
  data.frame(
    metric = c("Min", "Q1", "Median", "Mean", "Q3", "Max"),
    COMPASScovar = as.numeric(summary(fit$sim.fit$fit$A_gamma)),
    COMPASS = as.numeric(summary(fit$compass.fit$fit$fit$A_gamma))
  )
})
```


### True Values

#### Proportion Stim - Unstim vs Chemokine X

```{r}
sim.out.list[[1]]$beta.true.final
```

```{r}
sim.out.list[[1]]$omega[1:5,]
```

```{r}
sim.out.list[[1]]$gamma.m[1:5,]
```

```{r}
sim.out.list[[1]]$sim.fit$data$n_u[1:5,]
```

```{r}
sim.out.list[[1]]$sim.fit$data$n_s[1:5,]
```


```{r fig.width = 4, fig.height = 3}
lapply(sim.out.list, FUN = function(sim) {
  #Find the differences in proportions between stim and unstim
  diff <- (sim$sim.fit$data$n_s / rowSums(sim$sim.fit$data$n_s)) - (sim$sim.fit$data$n_u / rowSums(sim$sim.fit$data$n_u))
  
  #Make a dataframe
  diff.df <- data.frame(hiv = as.factor(sim$sim.fit$data$meta$hiv),
                        diff
  )
  
  #Rename columns
  colnames(diff.df) <- gsub("^X", "cluster", colnames(diff.df))
  
  #Loop over each cluster/marker
  plot.out.list <-
    lapply(grep('cluster', colnames(diff.df), value = T), FUN = function(cluster) {
      plot.out <-
        #Plot as a function of HIV status
        ggplot(data = diff.df %>%
                          select(c(hiv,
                                   {{cluster}}
                          )
                   ),
                   aes_string(x = cluster,
                              y = "hiv",
                              fill = "hiv"
                   )
        )+
        tidybayes::stat_halfeye()+
        geom_jitter(width = 0,
                    height = 0.1,
                    alpha = 0.4,
                    size = 0.7
        )+
        theme_bw()+
        ylab("Cytokine X Presence")+
        xlab("Prop. Stim - Prop. Unstim")+
        scale_fill_discrete(name = "Cytokine X\npresence")+
        scale_x_continuous(breaks = seq.default(from = -1,
                                                to = 1, 
                                                by = 0.005
                           )
        )+
        labs(title = stringr::str_to_title({{cluster}}))
    })
  
  return(plot.out.list)
})
```

##### Examine Outlier Values

Set up diff dataframe
```{r}
#Find the differences in proportions between stim and unstim
diff <- (sim.out.list[[1]]$sim.fit$data$n_s / rowSums(sim.out.list[[1]]$sim.fit$data$n_s)) - (sim.out.list[[1]]$sim.fit$data$n_u / rowSums(sim.out.list[[1]]$sim.fit$data$n_u))

#Make a dataframe
diff.df <- data.frame(hiv = as.factor(sim.out.list[[1]]$sim.fit$data$meta$hiv),
                      diff
)

#Rename columns
colnames(diff.df) <- gsub("^X", "cluster", colnames(diff.df))
```

###### Cytokine Absent

Isolate samples
```{r}
diff.df %>%
    filter(cluster8 >= 0.07) %>%
    select(hiv, cluster8, cluster16)

cluster8.0.outliers <- 
  diff.df %>%
    filter(cluster8 >= 0.07) %>%
    select(hiv, cluster8, cluster16) %>%
    rownames()

data.frame(sim.out.list[[1]]$omega[as.integer(cluster8.0.outliers), ])
data.frame(sim.out.list[[1]]$gamma.m[as.integer(cluster8.0.outliers), ])
```

**Notes:**

- All samples either have only subset 8 stimulated or subset 8 + one other subset stimulated
- The omega values suggest that these subsets were stimulated by chance (all only about 5%)

Examine an outlier sample
```{r}
i = 65

#True stimulated subsets
sim.out.list[[1]]$gamma.m[i,]

# Draw prob vector from Dirichlet for unstim
p_u.test <- rdirichlet(n = 1, alpha = alpha_u[i,])

# Copy prob vector for unstim and assign to stim
p_s.test <- p_u.test

#Concentration for stimulated subsets
alpha_s[i, c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]

#Old stimulated probs
p_s.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]

# For subsets where gamma == 1, draw new probabilities from Dirichlet using stim concentrations, and normalize (see note above)
p_s.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)] <- rdirichlet(n = 1, alpha = alpha_s[i, c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]) * sum(p_u.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)])

#New stimulated probs
p_s.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]

(p_s.test / sum(p_s.test)) - (p_u.test / sum(p_u.test))
```

Examine a non-outlier sample (subset 8 not truly responding)
```{r}
i = 72

#True stimulated subsets
sim.out.list[[1]]$gamma.m[i,]

# Draw prob vector from Dirichlet for unstim
p_u.test <- rdirichlet(n = 1, alpha = alpha_u[i,])

# Copy prob vector for unstim and assign to stim
p_s.test <- p_u.test

# Concentration for stimulated subsets
alpha_s[i, c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]

p_s.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]

# For subsets where gamma == 1, draw new probabilities from Dirichlet using stim concentrations, and normalize (see note above)
p_s.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)] <- rdirichlet(n = 1, alpha = alpha_s[i, c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]) * sum(p_u.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)])

#New stimulated probs
p_s.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]

(p_s.test / sum(p_s.test)) - (p_u.test / sum(p_u.test))
```

Probs from concentration parameters mimicking an outlier vs not
```{r}
p_u <- rdirichlet(n = 1, alpha = c(50, 50, 50, 50, 50, 50, 50, 500))


rdirichlet(n = 1, alpha = c(200, 500))

rdirichlet(n = 1, alpha = c(2000, 2000, 2000, 2000, 2000, 2000, 500))
```

**Explanation:** The outliers when cytokine is absent have higher difference in prop stim - prop unstim because there is only a single cell subset that responds by chance. This results in a higher proportion for that single subset compared to when multiple subsets are responding because they all must sum to 1. See example above.



###### Cytokine Present

Isolate samples
```{r}
diff.df %>%
    filter(cluster8 >= 0.01 & cluster8 <= 0.05) %>%
    select(hiv, cluster8, cluster16)

cluster8.1.outliers <- 
  diff.df %>%
    filter(cluster8 >= 0.01 & cluster8 <= 0.05) %>%
    select(hiv, cluster8, cluster16) %>%
    rownames()

data.frame(sim.out.list[[1]]$omega[as.integer(cluster8.1.outliers), ])
data.frame(sim.out.list[[1]]$gamma.m[as.integer(cluster8.1.outliers), ])
```


**Notes:**

- All samples have multiple subsets stimulated apart from subset 8
- The omega values for subset 8 for these samples suggest that they were stimulated by chance (only ~ 5% prob)


Examine an outlier sample
```{r}
i = 148

#True stimulated subsets
sim.out.list[[1]]$gamma.m[i,]

# Draw prob vector from Dirichlet for unstim
p_u.test <- rdirichlet(n = 1, alpha = alpha_u[i,])

# Copy prob vector for unstim and assign to stim
p_s.test <- p_u.test

#Concentration for stimulated subsets
alpha_s[i, c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]

#Old stimulated probs
p_s.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]

# For subsets where gamma == 1, draw new probabilities from Dirichlet using stim concentrations, and normalize (see note above)
p_s.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)] <- rdirichlet(n = 1, alpha = alpha_s[i, c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]) * sum(p_u.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)])

#New stimulated probs
p_s.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]

(p_s.test / sum(p_s.test)) - (p_u.test / sum(p_u.test))
```

Examine a non-outlier sample (subset 8 not truly responding)
```{r}
i = 152

#True stimulated subsets
sim.out.list[[1]]$gamma.m[i,]

# Draw prob vector from Dirichlet for unstim
p_u.test <- rdirichlet(n = 1, alpha = alpha_u[i,])

# Copy prob vector for unstim and assign to stim
p_s.test <- p_u.test

# Concentration for stimulated subsets
alpha_s[i, c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]

p_s.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]

# For subsets where gamma == 1, draw new probabilities from Dirichlet using stim concentrations, and normalize (see note above)
p_s.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)] <- rdirichlet(n = 1, alpha = alpha_s[i, c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]) * sum(p_u.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)])

#New stimulated probs
p_s.test[c(which(sim.out.list[[1]]$gamma.m[i,] == 1), K)]

(p_s.test / sum(p_s.test)) - (p_u.test / sum(p_u.test))
```

**Explanation:** The outliers when cytokine is present but the subset is not stimulated have been stimulated by chance. Because this occurs in the cytokine present sample, there are many other subsets that are also stimulated, so the proportion for these stimulated by chance samples is relatively low for this subset. In contrast, the subsets that are stimulated by chance in the cytokine absent samples have higher proportions because few other (if any) subsets are stimulated.



#### True PFS vs True Protection

```{r}
lapply(sim.out.list, FUN = function(sim) {
  #Linear predictor vs PFS
  plot1 <-
  ggplot(data = sim$sim.fit$data$meta,
         aes(
           x = pfs.true.pfs,
           y = binomial()$linkfun(protect.prob.true)
         )
  )+
  geom_point()+
  geom_abline(intercept = beta.p[1],
              slope = beta.p[2]
  )+
  xlim(-2, 2)
  
  #Probability of protection vs PFS
  plot2 <- 
  ggplot(data = sim$sim.fit$data$meta,
         aes(
           x = pfs.true.pfs,
           y = protect.prob.true
         )
  )+
  geom_point()+
  xlim(-2, 2)+
  ylim(0, 1)
  
  #PFS vs protection outcome
  plot3 <-
  ggplot(data = sim$sim.fit$data$meta,
         aes(
           x = pfs.true.pfs,
           y = as.factor(protect.true)
         )
  )+
  geom_point()+
  tidybayes::stat_halfeye()
  
  return(list(plot1, plot2, plot3))
})

```




### Estimated Values

#### Mean Gamma vs Omega

```{r fig.width=6, fig.height=4}
lapply(sim.out.list, FUN = function(sim) {

  #Omega - mean_gamma
  omega.gamma.diff.covar <- sim$omega - sim$sim.fit$fit$mean_gamma[,1:sim$K1]
  omega.gamma.diff.compass <- sim$omega - sim$compass.fit$fit$fit$mean_gamma[,1:sim$K1]
  colnames(omega.gamma.diff.compass) <- NULL
  
  #Create datasets
  omega.gamma.diff.covar.df <- data.frame(hiv = as.factor(sim$sim.fit$data$meta$hiv),
                                          omega.gamma.diff.covar
  )
  omega.gamma.diff.compass.df <- data.frame(hiv = as.factor(sim$sim.fit$data$meta$hiv),
                                            omega.gamma.diff.compass
  )
  
  #Combine datasets in long format
  omega.gamma.diff.df <-
    bind_rows(
      omega.gamma.diff.covar.df %>%
        mutate(model = "COMPASScovariate"),
      omega.gamma.diff.compass.df %>%
        mutate(model = "COMPASS")
    )
  
  #Rename columns
  colnames(omega.gamma.diff.df) <- gsub("^X", "cluster", colnames(omega.gamma.diff.df))
  
  #Histograms
  hist.plot.list <-
    lapply(grep('cluster', colnames(omega.gamma.diff.df), value = T), FUN = function(cluster) {
      
      #Make the histogram for the current cluster
      hist.plot <-
        ggplot(data = omega.gamma.diff.df %>%
                      select(c(hiv,
                               model,
                               {{cluster}}
                      )
               ),
               aes_string(x = cluster,
                          fill = "hiv"
               )
        )+
        geom_histogram(bins = 80)+
        facet_grid(hiv ~ model)+
        theme_bw()+
        scale_x_continuous(breaks = seq.default(from = -1,
                                                to = 1,
                                                by = 0.25
                          )
        )+
        scale_fill_discrete(name = "Cytokine X\npresence")+
        ylab("Frequency")+
        xlab("Omega - Mean Gamma")+
        labs(title = stringr::str_to_title({{cluster}}))
      
      return(hist.plot)
    })
  
  return(hist.plot.list)
  
})
```

Look at COMPASScovariate Omega - mean.gamma
```{r}
lapply(sim.out.list, FUN = function(sim) {

  #Omega - mean_gamma
  omega.gamma.diff.covar <- sim$omega - sim$sim.fit$fit$mean_gamma[,1:sim$K1]
  omega.gamma.diff.compass <- sim$omega - sim$compass.fit$fit$fit$mean_gamma[,1:sim$K1]
  colnames(omega.gamma.diff.compass) <- NULL
  
  #Create datasets
  omega.gamma.diff.covar.df <- data.frame(hiv = as.factor(sim$sim.fit$data$meta$hiv),
                                          omega.gamma.diff.covar
  )
  omega.gamma.diff.compass.df <- data.frame(hiv = as.factor(sim$sim.fit$data$meta$hiv),
                                            omega.gamma.diff.compass
  )
  
  omega.gamma.diff.covar.df
  
})
```

Look at COMPASS omega - mean.gamma
```{r}
lapply(sim.out.list, FUN = function(sim) {

  #Omega - mean_gamma
  omega.gamma.diff.covar <- sim$omega - sim$sim.fit$fit$mean_gamma[,1:sim$K1]
  omega.gamma.diff.compass <- sim$omega - sim$compass.fit$fit$fit$mean_gamma[,1:sim$K1]
  colnames(omega.gamma.diff.compass) <- NULL
  
  #Create datasets
  omega.gamma.diff.covar.df <- data.frame(hiv = as.factor(sim$sim.fit$data$meta$hiv),
                                          omega.gamma.diff.covar
  )
  omega.gamma.diff.compass.df <- data.frame(hiv = as.factor(sim$sim.fit$data$meta$hiv),
                                            omega.gamma.diff.compass
  )
  
  omega.gamma.diff.compass.df
  # sim$sim.fit$fit$mean_gamma[,1:sim$K1]
  
})
```

#### Mean Gamma vs True Gamma

```{r}
lapply(sim.out.list, FUN = function(sim) {

  #Omega - mean_gamma
  true.gamma.diff.covar <- sim$gamma.m - sim$sim.fit$fit$mean_gamma[,1:sim$K1]
  true.gamma.diff.compass <- sim$gamma.m - sim$compass.fit$fit$fit$mean_gamma[,1:sim$K1]
  colnames(true.gamma.diff.compass) <- NULL
  
  #Create datasets
  true.gamma.diff.covar.df <- data.frame(hiv = as.factor(sim$sim.fit$data$meta$hiv),
                                          true.gamma.diff.covar
  )
  true.gamma.diff.compass.df <- data.frame(hiv = as.factor(sim$sim.fit$data$meta$hiv),
                                            true.gamma.diff.compass
  )
  
  #Combine datasets in long format
  true.gamma.diff.df <-
    bind_rows(
      true.gamma.diff.covar.df %>%
        mutate(model = "COMPASScovariate"),
      true.gamma.diff.compass.df %>%
        mutate(model = "COMPASS")
    )
  
  #Rename columns
  colnames(true.gamma.diff.df) <- gsub("^X", "cluster", colnames(true.gamma.diff.df))
  
  #Histograms
  hist.plot.list <-
    lapply(grep('cluster', colnames(true.gamma.diff.df), value = T), FUN = function(cluster) {
      
      #Make the histogram for the current cluster
      hist.plot <-
        ggplot(data = true.gamma.diff.df %>%
                      select(c(hiv,
                               model,
                               {{cluster}}
                      )
               ),
               aes_string(x = cluster,
                          fill = "hiv"
               )
        )+
        geom_histogram(bins = 80)+
        facet_grid(hiv ~ model)+
        theme_bw()+
        # scale_x_continuous(breaks = seq.default(from = -1,
        #                                         to = 1,
        #                                         by = 0.25
        #                   )
        # )+
        scale_fill_discrete(name = "Cytokine X\npresence")+
        ylab("Frequency")+
        xlab("True Gamma - Mean Gamma")+
        labs(title = stringr::str_to_title({{cluster}}))
      
      return(hist.plot)
    })
  
  return(hist.plot.list)
  
})
```


```{r}
lapply(sim.out.list, FUN = function(sim) {

  #Omega - mean_gamma
  true.gamma.diff.covar <- sim$gamma.m - sim$sim.fit$fit$mean_gamma[,1:sim$K1]
  true.gamma.diff.compass <- sim$gamma.m - sim$compass.fit$fit$fit$mean_gamma[,1:sim$K1]
  colnames(true.gamma.diff.compass) <- NULL
  
  #Create datasets
  true.gamma.diff.covar.df <- data.frame(hiv = as.factor(sim$sim.fit$data$meta$hiv),
                                          true.gamma.diff.covar
  )
  true.gamma.diff.compass.df <- data.frame(hiv = as.factor(sim$sim.fit$data$meta$hiv),
                                            true.gamma.diff.compass
  )

  bind_rows(
    true.gamma.diff.covar.df %>%
      select(-hiv) %>%
      summarize(Under.est = sum(rowSums(.) > 0),
                Over.est = sum(rowSums(.) < 0)
      ) %>%
      mutate(Model = "COMPASScov"),
    true.gamma.diff.compass.df %>%
      select(-hiv) %>%
      summarize(Under.est = sum(rowSums(.) > 0),
                Over.est = sum(rowSums(.) < 0)
      ) %>%
      mutate(Model = "COMPASS")
  )
  

  
})
```

```{r}
round(
      sum(sim$gamma.m == sim$sim.fit$fit$mean_gamma[,-ncol(sim$sim.fit$fit$mean_gamma)]) /
        (dim(sim$gamma.m)[1] * dim(sim$gamma.m)[2]) * 100,
      digits = 2
  )

  round(
      sum(sim$gamma.m == sim$compass.fit$fit$fit$mean_gamma[,-ncol(sim$compass.fit$fit$fit$mean_gamma)]) /
        (dim(sim$gamma.m)[1] * dim(sim$gamma.m)[2]) * 100,
      digits = 2
  )
```


#### Gammma from COMPASScovariate vs COMPASS

Add: Color by true gamma value

```{r}
lapply(sim.out.list, FUN = function(sim) {
  #Find the differences in mean gamma matrices between COMPASS and COMPASScovariate
  mean.gamma.diff <- sim$sim.fit$fit$mean_gamma - sim$compass.fit$fit$fit$mean_gamma
  
  #Remove colnames
  colnames(mean.gamma.diff) <- NULL
  
  #Create datasets
  mean.gamma.diff.df <- data.frame(hiv = as.factor(sim$sim.fit$data$meta$hiv),
                                   mean.gamma.diff
  )
  
  #Subset columns where there are any differences
  mean.gamma.diff <- mean.gamma.diff[, abs(colSums(mean.gamma.diff)) > 0]
  
  #Rename columns
  colnames(mean.gamma.diff.df) <- gsub("^X", "cluster", colnames(mean.gamma.diff.df))
  
  #Histograms
  plot.list <-
    lapply(grep('cluster', colnames(mean.gamma.diff.df), value = T), FUN = function(cluster) {
    
      plot <-
        ggplot(data = mean.gamma.diff.df %>%
                        select(c(hiv,
                                 {{cluster}}
                        )
                 ),
                 aes_string(x = cluster,
                            y = "hiv"
                 )
        )+
        tidybayes::stat_halfeye()+
        geom_jitter(width = 0,
                    height = 0.1
        )+
        theme_bw()+
        ylab("Cytokine X Presence")+
        xlab("Mean Gamma COMPASScov - COMPASS")+
        labs(title = stringr::str_to_title({{cluster}}))
      
      return(plot)
    })
})
```

#### Variance of Gamma Posteriors

Is the precision of the estimates lower for COMPASS without a covariate?

```{r}
#Loop over columns
apply(
  #Find differences in variance between COMPASS - COMPASScov for all I x K
  apply(sim.out.list[[1]]$compass.fit$fit$fit$gamma, MARGIN = c(1,2), var) - 
    apply(sim.out.list[[1]]$sim.fit$fit$gamma, MARGIN = c(1,2), var),
  MARGIN = 2,
  FUN = function(x) {
    
    #Make a dataframe of the Kth subset var diffs
    dat = data.frame(
      diff.precision = x
    )
    
    #Plot a histogram of the var diffs
    ggplot(data = dat,
           aes(x = diff.precision)
    )+
    geom_histogram()
  }
)
  
```



#### Mean Gamma vs Prop Stim - Unstim

Does COMPASScovariate pick up the signal from the age covariate via mean gamma? 


## Compare Estimates to True

Create a custom function for calculating the mode
```{r}
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
```

```{r}
fits.out <- 
lapply(sim.out.list, FUN = function(sim) {
  #Give shortcut names to objects from sim.out.list
  I <- sim$I
  K <- sim$K
  K1 <- sim$K1
  p <- sim$p
  sim_rep <- sim$sim_rep
  sim.fit <- sim$sim.fit
  compass.fit <- sim$compass.fit
  gamma.m <- sim$gamma.m
  beta.true.final <- sim$beta.true.final
  
  #Create an out directory
  out.dir.loop <- file.path(out.dir,
                            paste(paste0("I:", I),
                                  paste0("K:", K),
                                  paste0("p:", p),
                                  paste0("rep:", sim_rep),
                                  sep = "_"
                                  )
                                )
  
  out.fig.dir.loop <- file.path(out.dir.loop,
                                "figures")
  out.obj.dir.loop <- file.path(out.dir.loop,
                                   "objects")
  dir.create(out.dir.loop, showWarnings = FALSE)
  dir.create(out.fig.dir.loop, showWarnings = FALSE)
  dir.create(out.obj.dir.loop, showWarnings = FALSE)
  
  ###################################################################################
  ### Gamma
  sim.fit.gamma <- apply(sim.fit$fit$gamma, MARGIN = c(1,2), FUN = function(x) getmode(x))
  ## Percent correct
  percent.gamma.correct <-
    # paste(
      # "Percent gamma correct (excluding Kth subset):",
      round(
        sum(gamma.m == sim.fit.gamma[,-ncol(sim.fit.gamma)]) /
          (dim(gamma.m)[1] * dim(gamma.m)[2]) * 100,
        digits = 2
      # )
    )
  
  #########Compass
  compass.fit.gamma <- apply(compass.fit$fit$fit$gamma, MARGIN = c(1,2), FUN = function(x) getmode(x))
  ##Percent COMPASS correct
  percent.gamma.correct.compass <-
    round(
        sum(gamma.m == compass.fit.gamma[,-ncol(compass.fit.gamma)]) /
          (dim(gamma.m)[1] * dim(gamma.m)[2]) * 100,
        digits = 2
    )
  
  ##########################################################################################
  ### Betas
  sim.fit.beta.median <- apply(sim.fit$fit$beta, MARGIN = c(1,2), FUN = function(x) median(x))
  
  ##Coverage
  #Find 95% quantile intervals
  lower.95 <- apply(sim.fit$fit$beta, MARGIN = c(1,2), FUN = function(x) quantile(x,
                                                                 prob = 0.025
                                                                 )
      )
  upper.95 <- apply(sim.fit$fit$beta, MARGIN = c(1,2), FUN = function(x) quantile(x,
                                                                 prob = 0.975
                                                                 )
      )
  #Find percentage of true values outside of 95% quantile interval
  beta.coverage <- beta.true.final >= lower.95 & beta.true.final <= upper.95
  percent.beta.coverage <-
    # paste(
      # "Percent true betas within 95% quantile interval:",
      round(
        sum(
          beta.coverage
        ) / length(beta.true.final) * 100,
        2
      # )
    )
  
  
  
  ##################
  ## Save Fit Object
  ##################
  
  saveRDS(sim.fit,
          file = file.path(out.obj.dir.loop,
                           paste(paste0("I:", I),
                                 paste0("K:", K),
                                 paste0("p:", p),
                                 paste0("rep:", sim_rep, ".RDS"),
                                 sep = "_"
                                )
                           )
          )
  
  #################
  ## Plot All Betas
  #################
  # 1. Extract beta draws into a dataframe with cluster and covariate indicators
  # 2. Row-bind together into long format
  # 3. Plot with x as cluster and y as covariate
  
  #Extract beta draws into a dataframe with cluster and covariate indicators
  cov.out <- list(NULL)
  cluster.out <- list(NULL)
  
  #Loop over each k-1 cluster
  for (k in 1:K1) {
    #Extract a matrix of draws x coefficients for current cluster
    cluster <- t(apply(sim.fit$fit$beta, MARGIN = c(2,3), FUN = function(x) x[k]))
    
    #Make a dataframe for each covariate (column) with current cluster and covariate ID
    for (cov in 1:(p+1)) { #p+1 b/c of intercept
      cov.out[[cov]] <- 
        data.frame(cluster = k,
                 covariate = cov,
                 value = apply(cluster, MARGIN = 1, FUN = function(y) y[cov])
      )
    }
    
    #Combine the dataframes for each coefficient for the current cluster
    cluster.out[[k]] <- do.call('rbind', cov.out)
  }
  
  #Combine the dataframes for all clusters
  post.out <- do.call('rbind', cluster.out)

  #Check that rows of post.out match dimension of original beta draws
  post.out.dim.check <-
    dim(post.out)[1] ==
      dim(sim.fit$fit$beta)[1] * (dim(sim.fit$fit$beta)[2]) * dim(sim.fit$fit$beta)[3]

  #Make cluster and covariate factors
  post.out$cluster <- as.factor(post.out$cluster)
  post.out$covariate <- as.factor(post.out$covariate)

  ##Include true betas
  post.out$true.beta <- NA
  for (k in 1:K1) {
    for (cov in 1:(p+1)) {
      post.out$true.beta[post.out$cluster == k & post.out$covariate == cov] <- beta.true.final[k,cov]
    }
  }

  #Check that length of unique true.beta is equal to number of true betas
  true.beta.check <-
  (
  #Number of unique betas excluding duplicated 0s
  length(unique(post.out$true.beta)) +
    #Number of cluster-covariate combinations where true.beta is 0 minus 1 (b/c 1 true 0 already counted above) (unless only 1 true 0)
    ifelse(length(unique(paste(post.out$cluster[post.out$true.beta == 0], post.out$covariate[post.out$true.beta == 0]))) == 0,
      length(unique(paste(post.out$cluster[post.out$true.beta == 0], post.out$covariate[post.out$true.beta == 0]))),
      length(unique(paste(post.out$cluster[post.out$true.beta == 0], post.out$covariate[post.out$true.beta == 0]))) - 1
    )
  ) ==
    #Equal to dimension of true beta (without intercept?)
    length(beta.true.final)
  
  ##Make the plot
  #Mapping nice cluster names
  cluster_names <- c(
    "1" = "Subset 1",
    "2" = "Subset 2",
    "3" = "Subset 3",
    "4" = "Subset 4",
    "5" = "Subset 5",
    "6" = "Subset 6",
    "7" = "Subset 7",
    "8" = "Subset 8",
    "9" = "Subset 9",
    "10" = "Subset 10",
    "11" = "Subset 11",
    "12" = "Subset 12",
    "13" = "Subset 13",
    "14" = "Subset 14",
    "15" = "Subset 15",
    "16" = "Subset 16",
    "17" = "Subset 17"
  )
  
  beta.post.true.plot <- 
    ggplot(data = post.out,
           aes(y = covariate, x = value)
      )+
      geom_vline(xintercept = 0,
                 linewidth = 0.6,
                 color = "dark gray"
      )+
      tidybayes::stat_halfeye(aes(fill = after_stat(level)),
                              fatten_point = 0.85,
                              alpha = 0.6
      ) +
      geom_segment(
                   aes(x = true.beta,
                       y = as.integer(covariate) - 0.15,
                       yend = as.integer(covariate) + 0.15,
                       xend = true.beta
                    ),
                   linewidth = 0.2
      )+
      facet_wrap(~ cluster,
                 labeller = labeller(
                   cluster = cluster_names
                 ),
                 ncol = 4
      )+
      theme_bw()+
      xlab("Value")+
      ylab("Covariate")+
      scale_fill_brewer(name = "Credible\nlevel",
                        na.translate = FALSE,
                        palette = "Set1",
      )
  
  ##Save the plot
  ggsave(beta.post.true.plot,
         filename = file.path(out.fig.dir.loop,
                              paste0(
                                paste("beta.post.true.plot",
                                      paste0("I:", I),
                                      paste0("K:", K),
                                      paste0("p:", p),
                                      paste0("rep:", sim_rep),
                                      sep = "_"
                                ),
                                ".pdf"
                              )
                    ),
         width = 6,
         height = 3*(K1/4)
  )
  

  ###########################################
  #### Plot Posteriors Not Achieving Coverage
  ###########################################
  
  #Loop over rows of beta.diff and find row,col of estimates that fail to achieve coverage
  beta.no.cover.coord <- list(NULL)
  for (i in 1:nrow(beta.coverage)) {
    if(length(which(beta.coverage[i,] == FALSE)) > 0) {
      #Paste the row name (i) with the indices of the columns for the current row
      beta.no.cover.coord[[i]] <- paste(i, which(beta.coverage[i,] == FALSE), sep = ", ")
    } else {
      beta.no.cover.coord[[i]] <- NULL
    }
  }
  beta.no.cover.coord.df <- do.call('c', beta.no.cover.coord)
  
  #Extract and plot posterior samples for flagged coefs (if any)
  if (length(beta.no.cover.coord.df) > 0) {
    lapply(1:length(beta.no.cover.coord.df), FUN = function(i) {
      #Extract the posterior samples for the current beta
      post <- data.frame(samples = eval(parse(text = paste0("sim.fit$fit$beta",
                               "[",
                               beta.no.cover.coord.df[i],
                               ",]"
                               )
                                             )
                                       )
           )
      
      #Extract the true beta value
      true.beta <- eval(parse(text = paste0("beta.true.final",
                             "[",
                             beta.no.cover.coord.df[i],
                             "]"
                                       )
                         )
                   )
      
      #Make the plot
      beta.no.cover.post.plot <- 
        ggplot(data = post,
               aes(x = samples)
          )+
          theme_bw()+
          geom_vline(xintercept = 0,
                     size = 0.6,
                     color = "dark gray"
          )+
          geom_hline(yintercept = 0,
                     size = 0.6,
                     color = "dark gray"
          )+
          ggdist::stat_halfeye(
            .width = c(0.95, 0.8),
            point_interval = "median_qi"    #Use median for point est
          )+
          geom_vline(xintercept = true.beta,
                     color = "blue"
          )+
          xlab("Posterior sample")+
          labs(title = paste0("Cluster: ", 
                      stringr::str_split(beta.no.cover.coord.df[i],
                                         pattern = ", ",
                                         simplify = TRUE
                      )[1],
                      ", Covariate: ",
                      stringr::str_split(beta.no.cover.coord.df[i],
                                         pattern = ", ",
                                         simplify = TRUE
                      )[2]
                      )
          )
      
      ##Save the plot
      ggsave(beta.no.cover.post.plot,
             filename = file.path(out.fig.dir.loop,
                                  paste0(
                                    paste("beta.no.cover.post.plot",
                                          paste0("I:", I),
                                          paste0("K:", K),
                                          paste0("p:", p),
                                          paste0("rep:", sim_rep),
                                          paste(
                                            "cluster",
                                            stringr::str_split(beta.no.cover.coord.df[i],
                                                               pattern = ", ",
                                                               simplify = TRUE
                                            )[1],
                                            sep = "-"
                                          ),
                                          paste(
                                            "covariate",
                                            stringr::str_split(beta.no.cover.coord.df[i],
                                                               pattern = ", ",
                                                               simplify = TRUE
                                            )[2],
                                            sep = "-"
                                          ),
                                          sep = "_"
                                    ),
                                    ".pdf"
                                  )
                        ),
             width = 6,
             height = 4
      )
    })

  }
  
  mod.fit.list <- data.frame(
                    I = I,
                    K = K,
                    p = p,
                    Iters = iter,
                    Reps = rep,
                    Simulation.replicate = sim_rep,
                    Percent.gamma.correct = percent.gamma.correct,
                    percent.gamma.correct.compass = percent.gamma.correct.compass,
                    Percent.beta.95.coverage = percent.beta.coverage,
                    Post.out.check = post.out.dim.check,
                    True.beta.check = true.beta.check
  )
  
  return(mod.fit.list)
  
})
```

## Summarize

```{r}
sim.stats <- do.call('rbind', fits.out)

sim.stats
```

```{r}
sim.stats %>%
  dplyr::group_by(I, K, p) %>%
  dplyr::summarize(
            iter = unique(iter),
            N = n(),
            Percent.gamma.correct.mean = round(mean(Percent.gamma.correct), 2),
            Percent.gamma.correct.COMPASS.mean = round(mean(percent.gamma.correct.compass), 2),
            Percent.gamma.correct.sd = round(sd(Percent.gamma.correct), 2),
            Percent.gamma.correct.COMPASS.sd = round(sd(percent.gamma.correct.compass), 2),
            Percent.beta.95.coverage.mean = round(mean(Percent.beta.95.coverage), 2),
            Percent.beta.95.coverage.sd = round(sd(Percent.beta.95.coverage), 2)
  )
```

## Save Output

```{r}

```


## Association Between PFS and Protection Outcome

### Plots

```{r}
lapply(sim.out.list, FUN = function(sim) {
  #Extract covariates from  metadata
  temp <- sim$sim.fit$data$meta
  
  #Add true protection status
  
  #Add polyfunctional scores from COMPASScovariate and COMPASS
  temp$compass.cov.pfs <- PolyfunctionalityScore(sim$sim.fit)
  temp$compass.pfs <- PolyfunctionalityScore(sim$compass.fit$fit)
  
  #Melt to long
  temp.long <-
    temp %>%
    tidyr::pivot_longer(.,
                        cols = c(compass.cov.pfs, compass.pfs),
                        names_to = "model",
                        values_to = "pfs"
    ) %>%
    #Make model names nice
    mutate(model = replace(model, model == "compass.cov.pfs", "COMPASScovariate"),
           model = replace(model, model == "compass.pfs", "COMPASS")
    )
  
  #Plot as a function of protection status
  ggplot(data = temp.long,
         aes(x = as.factor(protect.true),
             y = pfs
         )
  )+
  theme_bw()+
  geom_boxplot()+
  facet_wrap(~ model)+
  xlab("True Protection")+
  ylab("Polyfunctional score")
})
```

```{r}
sim.out.list[[1]]$sim.fit$data$meta

lapply(sim.out.list, FUN = function(sim) {
  #Extract covariates from  metadata
  temp <- sim$sim.fit$data$meta
  
  #Add polyfunctional scores from COMPASScovariate and COMPASS
  temp$compass.cov.pfs <- PolyfunctionalityScore(sim$sim.fit)
  temp$compass.pfs <- PolyfunctionalityScore(sim$compass.fit$fit)
  
  #Melt to long
  temp.long <-
    temp %>%
    tidyr::pivot_longer(.,
                        cols = c(compass.cov.pfs, compass.pfs),
                        names_to = "model",
                        values_to = "pfs"
    ) %>%
    #Make model names nice
    mutate(model = replace(model, model == "compass.cov.pfs", "COMPASScovariate"),
           model = replace(model, model == "compass.pfs", "COMPASS")
    )
  
  #Plot as a function of age
  ggplot(data = temp.long,
         aes(x = as.factor(hiv),
             y = pfs
         )
  )+
  theme_bw()+
  geom_point()+
  facet_wrap(~ model)+
  xlab("Cytokine X Presence")+
  ylab("Polyfunctional score")
})
```

```{r}
lapply(sim.out.list, FUN = function(sim) {
  #Extract covariates from  metadata
  temp <- sim$sim.fit$data$meta
  
  #Add polyfunctional scores from COMPASScovariate and COMPASS
  temp$compass.cov.pfs <- PolyfunctionalityScore(sim$sim.fit)
  temp$compass.pfs <- PolyfunctionalityScore(sim$compass.fit$fit)
  
  #Melt to long
  temp.long <-
    temp %>%
    tidyr::pivot_longer(.,
                        cols = c(compass.cov.pfs, compass.pfs),
                        names_to = "model",
                        values_to = "pfs"
    ) %>%
    #Make model names nice
    mutate(model = replace(model, model == "compass.cov.pfs", "COMPASScovariate"),
           model = replace(model, model == "compass.pfs", "COMPASS")
    )
  
  #Plot as a function of age
  ggplot(data = temp.long,
         aes(x = pfs.true.pfs,
             y = pfs
         )
  )+
  theme_bw()+
  geom_point()+
  geom_abline(intercept = 0, slope = 1)+
  facet_wrap(~ model)+
  xlab("True polyfunctional score")+
  ylab("Polyfunctional score")
})
```


### Logistic Regression

```{r}
log.reg.PFS <- 
  do.call('rbind',
    lapply(sim.out.list, FUN = function(fit) {
        #Extract covariates from  metadata
        temp <- fit$sim.fit$data$meta
        
        #Add polyfunctional scores from COMPASScovariate and COMPASS
        temp$compass.cov.pfs <- PolyfunctionalityScore(fit$sim.fit)
        temp$compass.pfs <- PolyfunctionalityScore(fit$compass.fit$fit)
        
        #Run logistic regressions for COMPASScovariate and COMPASS
        logreg.compass.cov <- summary(glm(protect.true ~ compass.cov.pfs, data = temp, family = binomial))
        logreg.compass <- summary(glm(protect.true ~ compass.pfs, data = temp, family = binomial))
        
        #Collect model output
        logreg.output <-
          bind_rows(
            logreg.compass.cov$coefficients %>%
              data.frame() %>%
              tibble::rownames_to_column(var = "Coef") %>%
              # filter(Model == "compass.cov.pfs") %>%
              mutate(Model = "COMPASScov",
                     Coef = replace(Coef, Coef == "compass.cov.pfs", "Cytokine"),
              ) %>%
              select(Coef, Model, Estimate, Pr...z..) %>%
              relocate(Model, .before = Coef),
            logreg.compass$coefficients %>%
              data.frame() %>%
              tibble::rownames_to_column(var = "Coef") %>%
              # filter(Model == "compass.cov.pfs") %>%
              mutate(Model = "COMPASS",
                     Coef = replace(Coef, Coef == "compass.pfs", "Cytokine"),
              ) %>%
              select(Coef, Model, Estimate, Pr...z..) %>%
              relocate(Model, .before = Coef)
          ) %>%
          mutate(I = fit$I,
                 K = fit$K,
                 p = fit$p,
                 rep = fit$sim_rep
          ) %>%
          arrange(Coef)
        
        return(logreg.output)
    })
  )
```

Display results
```{r}
log.reg.PFS %>%
  group_by(I, K, p, rep) %>%
  summarize(Model = Model,
            Coef = Coef,
            Estimate = Estimate,
            Pvalue = Pr...z..
  )
```

Logistic regression of true protection against true PFS
```{r}
lapply(sim.out.list, FUN = function(sim) {
  (
    coef(
      glm(protect.true ~ pfs.true.pfs,
          family = "binomial",
          data = sim$sim.fit$data$meta
        )
    )
  )
})
